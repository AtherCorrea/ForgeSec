# 2.2 - Decoding and Normalization

## ðŸ“š Index

- [What Is It?](#what-is-it)
- [How It Works](#how-it-works)
- [Why This Matters](#why-this-matters)
- [Practical Example â€“ TCP Stream Reassembly](#practical-example--tcp-stream-reassembly)
- [Visual Overview](#visual-overview)
- [Further Reference](#further-reference)

This section explores how IDS/IPS engines decode and normalize traffic before detection takes place. These processes are fundamental for reliable and consistent rule evaluation. Attackers often rely on malformed packets or fragmented streams to evade detection â€” decoding and normalization are what neutralize those tricks.

# What Is It?

**Decoding** is the process of parsing a packetâ€™s protocol layers â€” from Ethernet headers all the way to the application payload â€” so the IDS/IPS engine can understand whatâ€™s being transmitted.

**Normalization** is the act of cleaning, reconstructing, and standardizing that traffic to eliminate ambiguity and evasion techniques. This ensures the system has a clean, consistent view of the traffic, regardless of how fragmented or manipulated the original packets were.

Together, these stages form the foundation for detection accuracy.

### How It Works

#### Decoding

When a raw packet is ingested, the IDS/IPS engine must decode each protocol layer, usually from Layer 2 (Ethernet) up to Layer 7 (application). Each layer provides metadata needed by preprocessors and detection logic.

**Example of protocol decoding:**

| Layer         | Parsed Fields Example                                |
|---------------|------------------------------------------------------|
| Ethernet (L2) | Source MAC, Destination MAC                          |
| IP (L3)       | Source IP, Destination IP, Protocol                  |
| TCP/UDP (L4)  | Source Port, Destination Port, Flags, Sequence       |
| App Layer (L7)| HTTP Method, DNS Query, TLS SNI, MIME types, etc.    |

Decoding modules must be capable of handling multiple protocols and protocol versions. Many engines also include DPI (Deep Packet Inspection) to identify the application protocol even if it uses a non-standard port.

#### ðŸ§ª Normalization

Attackers often send packets in a way that exploits how different operating systems or IDS tools interpret edge cases â€” this is known as evasion. Normalization mitigates these risks by standardizing the traffic.

Key normalization tasks:

- **IP Fragment Reassembly**  
  Rebuilds complete datagrams from fragmented IP packets (common in evasion payloads).

- **TCP Stream Reassembly**  
  Reconstructs full TCP streams even when packets arrive out of order, are retransmitted, or overlap.

- **Handling Overlapping Segments**  
  Chooses a single interpretation of overlapping or ambiguous TCP segments. This must be consistent with the target system's behavior to avoid missing payloads.

- **Protocol Fixing / Header Cleanup**  
  Strips or fixes malformed HTTP headers, duplicate fields, or non-RFC-compliant values.

Many normalization decisions are based on "target-based" analysis â€” the IDS emulates the TCP/IP stack of the victim system (e.g., Windows, Linux) to mirror how it would interpret traffic.

### Why This Matters

Without decoding and normalization:

- Rules canâ€™t access correct protocol fields (e.g., `http.uri`, `tls.sni`)
- Evasion techniques like fragmentation, packet overlap, or header ambiguity may succeed
- Detection engines evaluate partial or misleading data, reducing accuracy
- Different behavior across IDS sensors and environments becomes harder to manage

These stages ensure detection is **consistent, predictable, and resistant to obfuscation**.

### Practical Example â€“ TCP Stream Reassembly

Suppose an attacker splits an HTTP request across multiple TCP packets to evade simple signature matching:

Packet 1: GET /evi
Packet 2: l.js HTTP/1.1

Without stream reassembly, the engine might never recognize the full request.

With proper normalization:

- The IDS/IPS reassembles the full stream: `GET /evil.js HTTP/1.1`
- The HTTP decoder now parses a complete request
- A rule like `content: "/evil.js"` successfully matches

This scenario is especially important in detecting web-based attacks, malware callbacks, or shellcode delivered in pieces.

### Visual Overview

[ Raw Packet Captured ]
        â†“
[ Decode Protocol Stack ]
        â†“
[ Reassemble Fragments and Streams ]
        â†“
[ Normalize Headers and Payloads ]
        â†“
[ Send Cleaned Traffic to Detection Engine ]

A mistake in any step here can cause the engine to **miss** the threat â€” or worse, allow the attacker to **bypass** your entire detection pipeline.

### Further Reference

- [Suricata â€“ Stream Reassembly Docs](https://docs.suricata.io/en/latest/configuration/stream-reassembly.html)
- [Evading Network Intrusion Detection Systems â€“ Ptacek & Newsham, 1998](https://insecure.org/stf/secnet_ids/secnet_ids.html)
- [Zeek (Bro) Protocol Parsing Concepts](https://docs.zeek.org/en/current/frameworks/protocols.html)
- [RFC 815 â€“ IP Datagram Reassembly Algorithms](https://datatracker.ietf.org/doc/html/rfc815)
